#!/usr/bin/env python3
"""
5åˆ†é–“BGMç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

30ç§’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¤‡æ•°ç”Ÿæˆã—ã¦5åˆ†é–“ã®BGMã‚’ä½œæˆ
"""

import asyncio
import logging
import os
import sys
import tempfile
from pathlib import Path
from typing import List, Optional

import numpy as np
import soundfile as sf

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.schemas.ai_music import (
    AudioFormatEnum,
    IntensityEnum,
    MusicGenerationRequest,
    MusicGenreEnum,
)
from app.services.audiocraft_service import AudioCraftMusicGenerator

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LongBGMGenerator:
    """é•·æ™‚é–“BGMç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.generator = AudioCraftMusicGenerator()
        self.sample_rate = 32000
        
    async def generate_long_bgm(self, 
                               genre: MusicGenreEnum,
                               intensity: IntensityEnum,
                               total_duration: int = 300,  # 5åˆ†é–“
                               segment_duration: int = 30,
                               overlap_duration: int = 5,
                               output_filename: Optional[str] = None) -> str:
        """
        é•·æ™‚é–“BGMã‚’ç”Ÿæˆ
        
        Args:
            genre: éŸ³æ¥½ã‚¸ãƒ£ãƒ³ãƒ«
            intensity: å¼·åº¦
            total_duration: ç·æ™‚é–“ï¼ˆç§’ï¼‰
            segment_duration: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰
            overlap_duration: ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æ™‚é–“ï¼ˆç§’ï¼‰
            output_filename: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if output_filename is None:
            output_filename = f"long_bgm_{genre.value}_{intensity.value}_{total_duration}s.wav"
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°è¨ˆç®—
        effective_segment_duration = segment_duration - overlap_duration
        num_segments = int(np.ceil(total_duration / effective_segment_duration))
        
        logger.info(f"Generating {total_duration}s BGM with {num_segments} segments")
        
        segments_audio = []
        
        for i in range(num_segments):
            logger.info(f"Generating segment {i+1}/{num_segments}")
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
            request = MusicGenerationRequest(
                genre=genre,
                intensity=intensity,
                duration=segment_duration,
                format=AudioFormatEnum.WAV
            )
            
            try:
                # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
                track, audio_data = await self.generator.generate_music(request)
                
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’NumPyé…åˆ—ã«å¤‰æ›
                with tempfile.NamedTemporaryFile(suffix=".wav") as tmp_file:
                    tmp_file.write(audio_data)
                    tmp_file.flush()
                    
                    audio_array, _ = sf.read(tmp_file.name)
                
                segments_audio.append(audio_array)
                logger.info(f"âœ“ Segment {i+1} generated ({len(audio_array)} samples)")
                
            except Exception as e:
                logger.error(f"âœ— Failed to generate segment {i+1}: {e}")
                raise
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¹‹ã’ã‚‹ï¼ˆã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰ï¼‰
        logger.info("Stitching segments together...")
        combined_audio = self._stitch_segments(segments_audio, overlap_duration)
        
        # æŒ‡å®šæ™‚é–“ã«ãƒˆãƒªãƒ 
        target_samples = int(total_duration * self.sample_rate)
        if len(combined_audio) > target_samples:
            combined_audio = combined_audio[:target_samples]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        output_path = Path(output_filename)
        sf.write(output_path, combined_audio, self.sample_rate, format='WAV', subtype='PCM_16')
        
        logger.info(f"ğŸµ Long BGM saved: {output_path} ({len(combined_audio)/self.sample_rate:.1f}s)")
        return str(output_path)
    
    def _stitch_segments(self, segments: List[np.ndarray], overlap_duration: int) -> np.ndarray:
        """
        ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰ã§ç¹‹ã’ã‚‹
        
        Args:
            segments: éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸€è¦§
            overlap_duration: ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—æ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            çµåˆã•ã‚ŒãŸéŸ³å£°
        """
        if not segments:
            return np.array([])
        
        if len(segments) == 1:
            return segments[0]
        
        overlap_samples = int(overlap_duration * self.sample_rate)
        combined = segments[0].copy()
        
        for i in range(1, len(segments)):
            current_segment = segments[i]
            
            if len(combined) < overlap_samples or len(current_segment) < overlap_samples:
                # ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã§ããªã„å ´åˆã¯å˜ç´”çµåˆ
                combined = np.concatenate([combined, current_segment])
            else:
                # ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰å‡¦ç†
                fade_out = np.linspace(1.0, 0.0, overlap_samples)
                fade_in = np.linspace(0.0, 1.0, overlap_samples)
                
                # å‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æœ€å¾Œéƒ¨åˆ†
                end_part = combined[-overlap_samples:] * fade_out
                # ç¾ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æœ€åˆéƒ¨åˆ†
                start_part = current_segment[:overlap_samples] * fade_in
                
                # ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰éƒ¨åˆ†ã‚’ä½œæˆ
                crossfade = end_part + start_part
                
                # çµåˆ
                combined = np.concatenate([
                    combined[:-overlap_samples],  # å‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—éƒ¨åˆ†é™¤ãï¼‰
                    crossfade,                    # ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰éƒ¨åˆ†
                    current_segment[overlap_samples:]  # ç¾ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—éƒ¨åˆ†é™¤ãï¼‰
                ])
        
        return combined


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Long BGM Generator")
    parser.add_argument("--genre", default="sleep", 
                       choices=["sleep", "ambient", "meditation", "nature_sounds"],
                       help="Music genre")
    parser.add_argument("--intensity", default="low",
                       choices=["low", "medium", "high"],
                       help="Music intensity")
    parser.add_argument("--duration", type=int, default=300,
                       help="Total duration in seconds (default: 300s = 5 minutes)")
    parser.add_argument("--output", default=None,
                       help="Output filename")
    
    args = parser.parse_args()
    
    # Enumå¤‰æ›
    genre = MusicGenreEnum(args.genre)
    intensity = IntensityEnum(args.intensity)
    
    print(f"ğŸµ Generating {args.duration}s {genre.value} BGM ({intensity.value} intensity)")
    print(f"Using MusicGen-medium model...")
    print()
    
    generator = LongBGMGenerator()
    
    try:
        output_file = await generator.generate_long_bgm(
            genre=genre,
            intensity=intensity,
            total_duration=args.duration,
            output_filename=args.output
        )
        
        file_size_mb = Path(output_file).stat().st_size / (1024 * 1024)
        print(f"\nğŸ‰ BGM generation completed!")
        print(f"ğŸ“ File: {output_file}")
        print(f"ğŸ“Š Size: {file_size_mb:.1f} MB")
        print(f"â±ï¸  Duration: {args.duration}s ({args.duration/60:.1f} minutes)")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Generation interrupted by user")
    except Exception as e:
        logger.error(f"Generation failed: {e}")
        print(f"\nâŒ Generation failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())